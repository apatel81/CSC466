{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name(s)\n",
    "**Ethan Moore and Ajay Patel**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Should we grade this notebook? (Answer yes or no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** Pair programming assignment. Submit only a single notebook unless you deviate significantly after lab on Thursday. If you submit individually, make sure you indicate who you worked with originally. Make sure to include your first and last names. For those students who push to individual repos but still work in groups, please indicate which notebook should be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning and Perceptron\n",
    "\n",
    "## Lab Assignment\n",
    "\n",
    "This is a pair programming assignment. I strongly\n",
    "discourage individual work for this (and other team/pair programming) lab(s), even if you think you can do it\n",
    "all by yourself. Also, this is a pair programming assignment, not a ”work in teams of two” assignment. Pair\n",
    "programming requires joint work on all aspects of the project without delegating portions of the work to individual\n",
    "1\n",
    "team members. For this lab, I want all your work — discussion, software development, analysis of the results,\n",
    "report writing — to be products of joint work.\n",
    "Students enrolled in the class can pair with other students enrolled in the class. Students on the waitlist can\n",
    "pair with other students on the waitlists. In the cases of ”odd person out” situations, a team of three people can\n",
    "be formed, but that team must (a) ask and answer one additional question, and (b) work as a pair would, without\n",
    "delegation of any work off-line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At the end of this lab, I should be able to\n",
    "* Formulate your own questions and understand how you can go about getting answers\n",
    "* Understand how to select an algorithm for your task\n",
    "* Implement ensemble methods gradient boosting and random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our data\n",
    "We will be using a well known housing dataset from Boston.\n",
    "<pre>\n",
    "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
    " prices and the demand for clean air', J. Environ. Economics & Management,\n",
    " vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
    " ...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
    " pages 244-261 of the latter.\n",
    "\n",
    " Variables in order:\n",
    " CRIM     per capita crime rate by town\n",
    " ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    " INDUS    proportion of non-retail business acres per town\n",
    " CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    " NOX      nitric oxides concentration (parts per 10 million)\n",
    " RM       average number of rooms per dwelling\n",
    " AGE      proportion of owner-occupied units built prior to 1940\n",
    " DIS      weighted distances to five Boston employment centres\n",
    " RAD      index of accessibility to radial highways\n",
    " TAX      full-value property-tax rate per $10,000\n",
    " PTRATIO  pupil-teacher ratio by town\n",
    " B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    " LSTAT    % lower status of the population\n",
    " MEDV     Median value of owner-occupied homes in $1000's\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"boston_fixed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.** Read the descriptions of the questions above, and come up with three reasonable questions with corresponding methods to test them. The only one that you cannot write, is the one we will do as a class, which I use as an example here:\n",
    "\n",
    "Example questions: \n",
    "* What are factors that are most predictive of the median value of owner-occupied homes? \n",
    "* Is there a small subset of the total number of variables that could be used in predictive model and not sacrifice model accuracy?\n",
    "* Can we say that any of these factors are causing the median home values to go up? \n",
    "\n",
    "Methodology:\n",
    "1. Empirically determine the best modeling method from our known list of ensemble learners and decision trees.\n",
    "2. Using this best model, compute a feature importance score\n",
    "3. Graph the feature importance score and see if this is a dip. Use this as a cutoff if so, if not, then select the best N features and verify model performance does not change significantly.\n",
    "4. NO!!! We cannot say anything about causation with our machine learning models. There are a lot of good discussions out there on why we can't say much about casuation. [See this one for example](https://towardsdatascience.com/causality-in-machine-learning-101-for-dummies-like-me-f7f161e7383e). BUT we can say a bit about correlation and what features are impacting our overall model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions\n",
    "1. How does the variable b impact the median value of owner-occupied homes when b is included vs not included in modeling/testing?\n",
    "2. Is there evidence that being near non-retail businesses increases median value of owner-occupied home?\n",
    "3. What is the relationship between tax and median value of owner-occupied homes?\n",
    "\n",
    "Methodology\n",
    "1. In our various models, we can include the variable b and exclude the variable. We can use a combination of recall, precision, and f1 to determine this.\n",
    "2. We can compare the median value of owner-occupied home with and without the non-retail businesses variable and test if the difference is significant.\n",
    "3. We can calculate the R-squared value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the next few questions, we will lean heavily upon sklearn and the built-in models. We'll implement our own methods later in the lab, but this is better to provide a consistent experience.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises 2-9**\n",
    "What are the factors that are most predictive of the median value of owner-occupied homes? Use the following methodology:\n",
    "\n",
    "1. Empirically determine the best modeling method from our known list of ensemble learners and decision trees (see code for more details)\n",
    "2. Using this best model, compute a feature importance score and rank the features by this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to get you started\n",
    "I included all of the imports I used in this section right here. I encourage you to take a look at their documentation. I also encourage you to try and mess with the parameters yourself and see if you can come up with better combinations. Finally, you can completely break the overall flow of what I've laid out as long as you accomplish the main goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# this is for plotting\n",
    "%matplotlib inline \n",
    "\n",
    "import copy\n",
    "\n",
    "# our standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# of course we need to be able to split into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# we need a \"loss\" function\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# This is where we can get our models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# This is what I used for comparing my models\n",
    "import scipy.stats as stats\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "X = df.drop(\"MEDV\",axis=1)\n",
    "y = df[\"MEDV\"]\n",
    "\n",
    "# Below are sample arguments, manually modify some of them and see what happens (we'll do this another time with grid search)\n",
    "# Fit regression model\n",
    "params = {'n_estimators': 500, 'max_depth': 2, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "gb_1 = ensemble.GradientBoostingRegressor(**params)\n",
    "params = {'n_estimators': 500, 'max_depth': 5, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "gb_2 = ensemble.GradientBoostingRegressor(**params)\n",
    "regr_1 = DecisionTreeRegressor(max_depth=2)\n",
    "regr_2 = DecisionTreeRegressor(max_depth=5)\n",
    "rf_1 = RandomForestRegressor(n_estimators=100)\n",
    "rf_2 = RandomForestRegressor(n_estimators=500)\n",
    "\n",
    "models = [('Gradient Boosting 1',gb_1),('Gradient Boosting 2',gb_2),\n",
    "          ('DTree 1',regr_1),('DTree 2',regr_2),\n",
    "          ('RF 1',rf_1),('RF 2',rf_2)\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** Fill in the following code that finds the mean squared error for 30 repeated hold-out cross-validation experiments for each classifier. In other words, fill in my code and produce something similar to my output. It is very important to realize that you will get different numbers since this is stochastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 30\n",
    "model_list = []\n",
    "predictions = []\n",
    "ytests = []\n",
    "mses = []\n",
    "for iteration in range(num_iterations):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.10,shuffle=True)\n",
    "    models_train = copy.deepcopy(models)\n",
    "    \n",
    "    for model in models_train:\n",
    "        model_list.append(model[0])\n",
    "        m = model[1].fit(Xtrain, ytrain)\n",
    "        predictions.append(m.predict(Xtest))\n",
    "        ytests.append(ytest)\n",
    "        mses.append(mean_squared_error(ytest, m.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dfs(first_num, mses, model_list):\n",
    "    temp = []\n",
    "    for i in range(first_num, 180, 6):\n",
    "        temp.append(mses[i])\n",
    "        df = pd.DataFrame(temp, columns=[model_list[first_num]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb1 = make_dfs(0, mses, model_list)\n",
    "gb2 = make_dfs(1, mses, model_list)\n",
    "dt1 = make_dfs(2, mses, model_list)\n",
    "dt2 = make_dfs(3, mses, model_list)\n",
    "rf1 = make_dfs(4, mses, model_list)\n",
    "rf2 = make_dfs(5, mses, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = gb1.join(gb2, how=\"left\").join(dt1, how=\"left\").join(dt2, how=\"left\").join(rf1, how=\"left\").join(rf2, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boosting 1</th>\n",
       "      <th>Gradient Boosting 2</th>\n",
       "      <th>DTree 1</th>\n",
       "      <th>DTree 2</th>\n",
       "      <th>RF 1</th>\n",
       "      <th>RF 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.727649</td>\n",
       "      <td>8.359413</td>\n",
       "      <td>42.138370</td>\n",
       "      <td>16.692046</td>\n",
       "      <td>12.754644</td>\n",
       "      <td>12.068526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17.079262</td>\n",
       "      <td>10.543040</td>\n",
       "      <td>44.933649</td>\n",
       "      <td>12.103425</td>\n",
       "      <td>10.333326</td>\n",
       "      <td>11.787014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.422600</td>\n",
       "      <td>9.935675</td>\n",
       "      <td>40.313458</td>\n",
       "      <td>13.318719</td>\n",
       "      <td>10.662598</td>\n",
       "      <td>10.968147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.809073</td>\n",
       "      <td>5.822245</td>\n",
       "      <td>35.382689</td>\n",
       "      <td>16.599815</td>\n",
       "      <td>8.672270</td>\n",
       "      <td>9.656926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12.386060</td>\n",
       "      <td>6.753628</td>\n",
       "      <td>30.102343</td>\n",
       "      <td>10.073797</td>\n",
       "      <td>8.016599</td>\n",
       "      <td>8.862199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gradient Boosting 1  Gradient Boosting 2    DTree 1    DTree 2       RF 1  \\\n",
       "0            17.727649             8.359413  42.138370  16.692046  12.754644   \n",
       "1            17.079262            10.543040  44.933649  12.103425  10.333326   \n",
       "2            19.422600             9.935675  40.313458  13.318719  10.662598   \n",
       "3            11.809073             5.822245  35.382689  16.599815   8.672270   \n",
       "4            12.386060             6.753628  30.102343  10.073797   8.016599   \n",
       "\n",
       "        RF 2  \n",
       "0  12.068526  \n",
       "1  11.787014  \n",
       "2  10.968147  \n",
       "3   9.656926  \n",
       "4   8.862199  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boosting 1</th>\n",
       "      <th>Gradient Boosting 2</th>\n",
       "      <th>DTree 1</th>\n",
       "      <th>DTree 2</th>\n",
       "      <th>RF 1</th>\n",
       "      <th>RF 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>14.322175</td>\n",
       "      <td>10.517962</td>\n",
       "      <td>32.196046</td>\n",
       "      <td>22.018548</td>\n",
       "      <td>11.836411</td>\n",
       "      <td>11.624347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>5.360408</td>\n",
       "      <td>5.974612</td>\n",
       "      <td>9.923907</td>\n",
       "      <td>14.427808</td>\n",
       "      <td>5.737549</td>\n",
       "      <td>5.487399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>5.655490</td>\n",
       "      <td>4.060663</td>\n",
       "      <td>11.007199</td>\n",
       "      <td>4.928707</td>\n",
       "      <td>3.841588</td>\n",
       "      <td>3.943534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>10.023812</td>\n",
       "      <td>6.281978</td>\n",
       "      <td>23.613271</td>\n",
       "      <td>13.224640</td>\n",
       "      <td>7.218448</td>\n",
       "      <td>7.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>14.850859</td>\n",
       "      <td>8.547716</td>\n",
       "      <td>34.790633</td>\n",
       "      <td>16.367320</td>\n",
       "      <td>10.497962</td>\n",
       "      <td>10.683591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>18.922309</td>\n",
       "      <td>12.191402</td>\n",
       "      <td>39.901868</td>\n",
       "      <td>26.433021</td>\n",
       "      <td>14.918540</td>\n",
       "      <td>14.418058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>23.936295</td>\n",
       "      <td>30.816578</td>\n",
       "      <td>48.233988</td>\n",
       "      <td>70.029086</td>\n",
       "      <td>25.620731</td>\n",
       "      <td>25.563319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gradient Boosting 1  Gradient Boosting 2    DTree 1    DTree 2  \\\n",
       "count            30.000000            30.000000  30.000000  30.000000   \n",
       "mean             14.322175            10.517962  32.196046  22.018548   \n",
       "std               5.360408             5.974612   9.923907  14.427808   \n",
       "min               5.655490             4.060663  11.007199   4.928707   \n",
       "25%              10.023812             6.281978  23.613271  13.224640   \n",
       "50%              14.850859             8.547716  34.790633  16.367320   \n",
       "75%              18.922309            12.191402  39.901868  26.433021   \n",
       "max              23.936295            30.816578  48.233988  70.029086   \n",
       "\n",
       "            RF 1       RF 2  \n",
       "count  30.000000  30.000000  \n",
       "mean   11.836411  11.624347  \n",
       "std     5.737549   5.487399  \n",
       "min     3.841588   3.943534  \n",
       "25%     7.218448   7.428100  \n",
       "50%    10.497962  10.683591  \n",
       "75%    14.918540  14.418058  \n",
       "max    25.620731  25.563319  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** Perform a one-way ANOVA to determine if there are any significant differences between methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=29.921529093885745, pvalue=7.195576910870597e-22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.f_oneway(errors[\"Gradient Boosting 1\"].to_list(), errors[\"Gradient Boosting 2\"].to_list(), \n",
    "               errors[\"DTree 1\"].to_list(), errors[\"DTree 2\"].to_list(),\n",
    "               errors[\"RF 1\"].to_list(), errors[\"RF 2\"].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the one-way ANOVA there does seem to be at least one model that performs significantly better than another model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** Perform a post-hoc pairwise test with bonferroni multiple test correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boosting 1</th>\n",
       "      <th>Gradient Boosting 2</th>\n",
       "      <th>DTree 1</th>\n",
       "      <th>DTree 2</th>\n",
       "      <th>RF 1</th>\n",
       "      <th>RF 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Gradient Boosting 1</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.790007e-01</td>\n",
       "      <td>6.742425e-11</td>\n",
       "      <td>0.122646</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.846331e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gradient Boosting 2</td>\n",
       "      <td>1.790007e-01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.847593e-13</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DTree 1</td>\n",
       "      <td>6.742425e-11</td>\n",
       "      <td>1.847593e-13</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.035121</td>\n",
       "      <td>1.280280e-12</td>\n",
       "      <td>5.900444e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DTree 2</td>\n",
       "      <td>1.226455e-01</td>\n",
       "      <td>2.437093e-03</td>\n",
       "      <td>3.512111e-02</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.015798e-02</td>\n",
       "      <td>7.494439e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF 1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.280280e-12</td>\n",
       "      <td>0.010158</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF 2</td>\n",
       "      <td>8.846331e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.900444e-13</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Gradient Boosting 1  Gradient Boosting 2       DTree 1  \\\n",
       "Gradient Boosting 1        -1.000000e+00         1.790007e-01  6.742425e-11   \n",
       "Gradient Boosting 2         1.790007e-01        -1.000000e+00  1.847593e-13   \n",
       "DTree 1                     6.742425e-11         1.847593e-13 -1.000000e+00   \n",
       "DTree 2                     1.226455e-01         2.437093e-03  3.512111e-02   \n",
       "RF 1                        1.000000e+00         1.000000e+00  1.280280e-12   \n",
       "RF 2                        8.846331e-01         1.000000e+00  5.900444e-13   \n",
       "\n",
       "                      DTree 2          RF 1          RF 2  \n",
       "Gradient Boosting 1  0.122646  1.000000e+00  8.846331e-01  \n",
       "Gradient Boosting 2  0.002437  1.000000e+00  1.000000e+00  \n",
       "DTree 1              0.035121  1.280280e-12  5.900444e-13  \n",
       "DTree 2             -1.000000  1.015798e-02  7.494439e-03  \n",
       "RF 1                 0.010158 -1.000000e+00  1.000000e+00  \n",
       "RF 2                 0.007494  1.000000e+00 -1.000000e+00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scikit_posthocs as sp\n",
    "post_hoc = pd.DataFrame(sp.posthoc_ttest(errors.transpose().values, p_adjust='bonferroni'), \n",
    "                        columns=errors.columns, index=errors.columns)\n",
    "post_hoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** Which method(s) perform the best? Consider which methods you can actually say with certainty perform better than the rest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gradient Boosting 2    10.517962\n",
       "RF 2                   11.624347\n",
       "RF 1                   11.836411\n",
       "Gradient Boosting 1    14.322175\n",
       "DTree 2                22.018548\n",
       "DTree 1                32.196046\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.describe().loc[\"mean\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gradient Boosting 1    False\n",
       "Gradient Boosting 2     True\n",
       "DTree 1                 True\n",
       "DTree 2                 True\n",
       "RF 1                   False\n",
       "RF 2                   False\n",
       "Name: Gradient Boosting 2, dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_hoc[\"Gradient Boosting 2\"] < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting 2 performs the best and does not signifcantly perfom better than Gradient Boosting 1, DTree 1, DTree 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** Spoiler... There should be more a few models that we are unable to distinguish using 30 trials. Rerun your above analysis, but this time repeat it with 200 trials instead of 30. Is there now a clear winner? This can definitely take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 200\n",
    "model_list = []\n",
    "predictions = []\n",
    "ytests = []\n",
    "mses = []\n",
    "for iteration in range(num_iterations):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.10,shuffle=True)\n",
    "    models_train = copy.deepcopy(models)\n",
    "    \n",
    "    for model in models_train:\n",
    "        model_list.append(model[0])\n",
    "        m = model[1].fit(Xtrain, ytrain)\n",
    "        predictions.append(m.predict(Xtest))\n",
    "        ytests.append(ytest)\n",
    "        mses.append(mean_squared_error(ytest, m.predict(Xtest)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dfs(first_num, mses, model_list):\n",
    "    temp = []\n",
    "    for i in range(first_num, 1200, 6):\n",
    "        temp.append(mses[i])\n",
    "        df = pd.DataFrame(temp, columns=[model_list[first_num]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb1 = make_dfs(0, mses, model_list)\n",
    "gb2 = make_dfs(1, mses, model_list)\n",
    "dt1 = make_dfs(2, mses, model_list)\n",
    "dt2 = make_dfs(3, mses, model_list)\n",
    "rf1 = make_dfs(4, mses, model_list)\n",
    "rf2 = make_dfs(5, mses, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = gb1.join(gb2, how=\"left\").join(dt1, how=\"left\").join(dt2, how=\"left\").join(rf1, how=\"left\").join(rf2, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boosting 1</th>\n",
       "      <th>Gradient Boosting 2</th>\n",
       "      <th>DTree 1</th>\n",
       "      <th>DTree 2</th>\n",
       "      <th>RF 1</th>\n",
       "      <th>RF 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11.987226</td>\n",
       "      <td>6.859747</td>\n",
       "      <td>20.293571</td>\n",
       "      <td>10.843788</td>\n",
       "      <td>7.788218</td>\n",
       "      <td>7.777887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13.078225</td>\n",
       "      <td>12.388672</td>\n",
       "      <td>44.985239</td>\n",
       "      <td>35.785516</td>\n",
       "      <td>15.413025</td>\n",
       "      <td>14.112784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11.585119</td>\n",
       "      <td>8.805987</td>\n",
       "      <td>24.674663</td>\n",
       "      <td>25.746260</td>\n",
       "      <td>9.778086</td>\n",
       "      <td>9.350877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.930000</td>\n",
       "      <td>11.936393</td>\n",
       "      <td>21.894930</td>\n",
       "      <td>39.149373</td>\n",
       "      <td>11.365300</td>\n",
       "      <td>11.510032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12.351671</td>\n",
       "      <td>6.766940</td>\n",
       "      <td>27.652516</td>\n",
       "      <td>17.907513</td>\n",
       "      <td>7.079514</td>\n",
       "      <td>6.476058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gradient Boosting 1  Gradient Boosting 2    DTree 1    DTree 2       RF 1  \\\n",
       "0            11.987226             6.859747  20.293571  10.843788   7.788218   \n",
       "1            13.078225            12.388672  44.985239  35.785516  15.413025   \n",
       "2            11.585119             8.805987  24.674663  25.746260   9.778086   \n",
       "3            10.930000            11.936393  21.894930  39.149373  11.365300   \n",
       "4            12.351671             6.766940  27.652516  17.907513   7.079514   \n",
       "\n",
       "        RF 2  \n",
       "0   7.777887  \n",
       "1  14.112784  \n",
       "2   9.350877  \n",
       "3  11.510032  \n",
       "4   6.476058  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boosting 1</th>\n",
       "      <th>Gradient Boosting 2</th>\n",
       "      <th>DTree 1</th>\n",
       "      <th>DTree 2</th>\n",
       "      <th>RF 1</th>\n",
       "      <th>RF 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Gradient Boosting 1</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>5.417692e-09</td>\n",
       "      <td>2.937006e-60</td>\n",
       "      <td>2.999226e-11</td>\n",
       "      <td>5.426305e-04</td>\n",
       "      <td>1.360568e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gradient Boosting 2</td>\n",
       "      <td>5.417692e-09</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>5.564400e-82</td>\n",
       "      <td>1.096493e-25</td>\n",
       "      <td>2.667109e-01</td>\n",
       "      <td>5.712125e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DTree 1</td>\n",
       "      <td>2.937006e-60</td>\n",
       "      <td>5.564400e-82</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>6.498055e-19</td>\n",
       "      <td>4.153297e-75</td>\n",
       "      <td>3.078768e-76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DTree 2</td>\n",
       "      <td>2.999226e-11</td>\n",
       "      <td>1.096493e-25</td>\n",
       "      <td>6.498055e-19</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.937247e-20</td>\n",
       "      <td>3.462018e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF 1</td>\n",
       "      <td>5.426305e-04</td>\n",
       "      <td>2.667109e-01</td>\n",
       "      <td>4.153297e-75</td>\n",
       "      <td>1.937247e-20</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF 2</td>\n",
       "      <td>1.360568e-04</td>\n",
       "      <td>5.712125e-01</td>\n",
       "      <td>3.078768e-76</td>\n",
       "      <td>3.462018e-21</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Gradient Boosting 1  Gradient Boosting 2       DTree 1  \\\n",
       "Gradient Boosting 1        -1.000000e+00         5.417692e-09  2.937006e-60   \n",
       "Gradient Boosting 2         5.417692e-09        -1.000000e+00  5.564400e-82   \n",
       "DTree 1                     2.937006e-60         5.564400e-82 -1.000000e+00   \n",
       "DTree 2                     2.999226e-11         1.096493e-25  6.498055e-19   \n",
       "RF 1                        5.426305e-04         2.667109e-01  4.153297e-75   \n",
       "RF 2                        1.360568e-04         5.712125e-01  3.078768e-76   \n",
       "\n",
       "                          DTree 2          RF 1          RF 2  \n",
       "Gradient Boosting 1  2.999226e-11  5.426305e-04  1.360568e-04  \n",
       "Gradient Boosting 2  1.096493e-25  2.667109e-01  5.712125e-01  \n",
       "DTree 1              6.498055e-19  4.153297e-75  3.078768e-76  \n",
       "DTree 2             -1.000000e+00  1.937247e-20  3.462018e-21  \n",
       "RF 1                 1.937247e-20 -1.000000e+00  1.000000e+00  \n",
       "RF 2                 3.462018e-21  1.000000e+00 -1.000000e+00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_hoc = pd.DataFrame(sp.posthoc_ttest(errors.transpose().values, p_adjust='bonferroni'), \n",
    "                        columns=errors.columns, index=errors.columns)\n",
    "post_hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gradient Boosting 2     9.747807\n",
       "RF 2                   10.766379\n",
       "RF 1                   10.924009\n",
       "Gradient Boosting 1    13.238558\n",
       "DTree 2                19.823827\n",
       "DTree 1                30.558813\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.describe().loc[\"mean\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gradient Boosting 1     True\n",
       "Gradient Boosting 2     True\n",
       "DTree 1                 True\n",
       "DTree 2                 True\n",
       "RF 1                   False\n",
       "RF 2                   False\n",
       "Name: Gradient Boosting 2, dtype: bool"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_hoc[\"Gradient Boosting 2\"] < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** Are there still any ties? If so, what are the best models? From there select the top model in terms of average error. Would this have been your same conclusion with only 30 experiments?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 200 iterations, Gradient Boosting 2 is still the best model, but once again, it is not significantly better than Gradient Boosting 1, DTree 1, and DTree 2. Therefore, this is the same conclusion as before when we ran 3o iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7** With you model of choice, calculate the mean_squared_error and r2_score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model of choice will be Gradient Boosting 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_preds = []\n",
    "for i in range(1, 1201, 6):\n",
    "    gb_preds.append(predictions[i])\n",
    "\n",
    "gb = pd.DataFrame(gb_preds).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_ytests = []\n",
    "for i in range(1, 1201, 6):\n",
    "    gb_ytests.append(ytests[i].values)\n",
    "    \n",
    "ys = pd.DataFrame(gb_ytests).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>18.3</td>\n",
       "      <td>28.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>21.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>...</td>\n",
       "      <td>21.9</td>\n",
       "      <td>20.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>33.2</td>\n",
       "      <td>19.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>23.9</td>\n",
       "      <td>18.6</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17.1</td>\n",
       "      <td>19.3</td>\n",
       "      <td>16.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>15.1</td>\n",
       "      <td>23.6</td>\n",
       "      <td>22.5</td>\n",
       "      <td>27.9</td>\n",
       "      <td>22.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>...</td>\n",
       "      <td>27.5</td>\n",
       "      <td>19.1</td>\n",
       "      <td>23.7</td>\n",
       "      <td>13.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>35.4</td>\n",
       "      <td>18.5</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>22.6</td>\n",
       "      <td>21.7</td>\n",
       "      <td>48.3</td>\n",
       "      <td>17.4</td>\n",
       "      <td>20.1</td>\n",
       "      <td>29.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>...</td>\n",
       "      <td>21.7</td>\n",
       "      <td>17.4</td>\n",
       "      <td>35.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>20.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>33.2</td>\n",
       "      <td>22.6</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>28.4</td>\n",
       "      <td>17.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>17.1</td>\n",
       "      <td>15.2</td>\n",
       "      <td>13.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.9</td>\n",
       "      <td>...</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.1</td>\n",
       "      <td>22.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>22.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>27.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>22.1</td>\n",
       "      <td>17.1</td>\n",
       "      <td>42.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>15.6</td>\n",
       "      <td>23.9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.3</td>\n",
       "      <td>13.8</td>\n",
       "      <td>21.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>31.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>20.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>18.2</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2     3     4     5     6     7     8     9    ...   190  \\\n",
       "0  17.5  18.3  28.5  15.0  31.7   7.0  15.0  30.8  21.2   8.8  ...  21.9   \n",
       "1  17.1  19.3  16.1  18.9  15.1  23.6  22.5  27.9  22.5  41.3  ...  27.5   \n",
       "2  21.8  15.0  24.4  22.6  21.7  48.3  17.4  20.1  29.9   8.3  ...  21.7   \n",
       "3  13.5  24.4  28.4  17.2  19.3  17.1  15.2  13.8  21.0  22.9  ...  19.9   \n",
       "4  27.9  18.4  16.3  22.1  17.1  42.3  13.3  15.6  23.9  29.0  ...  37.3   \n",
       "\n",
       "    191   192   193   194   195   196   197   198   199  \n",
       "0  20.7  18.0  10.2  33.2  19.7  21.4  23.9  18.6  20.5  \n",
       "1  19.1  23.7  13.5  50.0  18.0  19.1  35.4  18.5  12.5  \n",
       "2  17.4  35.2  14.3  17.2  20.4  41.3  33.2  22.6  19.5  \n",
       "3  20.1  22.6  22.0  23.3  19.3  20.3  22.9  14.0  23.6  \n",
       "4  13.8  21.9  29.1  31.6  22.6  20.3   8.8  18.2  50.0  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19.086043</td>\n",
       "      <td>20.775041</td>\n",
       "      <td>32.662159</td>\n",
       "      <td>27.347059</td>\n",
       "      <td>33.432155</td>\n",
       "      <td>9.001761</td>\n",
       "      <td>20.030982</td>\n",
       "      <td>28.690798</td>\n",
       "      <td>20.555787</td>\n",
       "      <td>8.942408</td>\n",
       "      <td>...</td>\n",
       "      <td>45.602515</td>\n",
       "      <td>21.945659</td>\n",
       "      <td>16.681802</td>\n",
       "      <td>14.369645</td>\n",
       "      <td>34.708164</td>\n",
       "      <td>19.911770</td>\n",
       "      <td>19.250785</td>\n",
       "      <td>26.258703</td>\n",
       "      <td>18.392011</td>\n",
       "      <td>20.915625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18.568518</td>\n",
       "      <td>19.923297</td>\n",
       "      <td>18.932132</td>\n",
       "      <td>17.107522</td>\n",
       "      <td>14.266230</td>\n",
       "      <td>24.135877</td>\n",
       "      <td>20.202173</td>\n",
       "      <td>30.432826</td>\n",
       "      <td>19.002506</td>\n",
       "      <td>37.307498</td>\n",
       "      <td>...</td>\n",
       "      <td>15.528705</td>\n",
       "      <td>21.573855</td>\n",
       "      <td>23.874679</td>\n",
       "      <td>13.465219</td>\n",
       "      <td>48.011769</td>\n",
       "      <td>17.491779</td>\n",
       "      <td>21.264077</td>\n",
       "      <td>35.055494</td>\n",
       "      <td>17.768116</td>\n",
       "      <td>14.787413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.809422</td>\n",
       "      <td>32.932002</td>\n",
       "      <td>22.991487</td>\n",
       "      <td>23.752759</td>\n",
       "      <td>20.598338</td>\n",
       "      <td>44.497664</td>\n",
       "      <td>19.672780</td>\n",
       "      <td>19.524344</td>\n",
       "      <td>28.380861</td>\n",
       "      <td>8.462188</td>\n",
       "      <td>...</td>\n",
       "      <td>21.248748</td>\n",
       "      <td>19.696959</td>\n",
       "      <td>44.722984</td>\n",
       "      <td>16.444413</td>\n",
       "      <td>18.726456</td>\n",
       "      <td>20.147961</td>\n",
       "      <td>38.258043</td>\n",
       "      <td>33.436345</td>\n",
       "      <td>22.443509</td>\n",
       "      <td>20.509242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>17.671078</td>\n",
       "      <td>23.916499</td>\n",
       "      <td>25.919748</td>\n",
       "      <td>19.409376</td>\n",
       "      <td>20.178503</td>\n",
       "      <td>17.916191</td>\n",
       "      <td>14.835005</td>\n",
       "      <td>14.725457</td>\n",
       "      <td>21.853383</td>\n",
       "      <td>23.238445</td>\n",
       "      <td>...</td>\n",
       "      <td>17.671723</td>\n",
       "      <td>18.987953</td>\n",
       "      <td>22.156860</td>\n",
       "      <td>22.247468</td>\n",
       "      <td>27.012871</td>\n",
       "      <td>20.511799</td>\n",
       "      <td>22.881815</td>\n",
       "      <td>20.780752</td>\n",
       "      <td>13.975789</td>\n",
       "      <td>24.301032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>27.970411</td>\n",
       "      <td>16.878918</td>\n",
       "      <td>15.371155</td>\n",
       "      <td>23.775365</td>\n",
       "      <td>19.159630</td>\n",
       "      <td>47.095129</td>\n",
       "      <td>13.187261</td>\n",
       "      <td>15.921431</td>\n",
       "      <td>27.086741</td>\n",
       "      <td>33.032481</td>\n",
       "      <td>...</td>\n",
       "      <td>33.817844</td>\n",
       "      <td>16.624787</td>\n",
       "      <td>44.027642</td>\n",
       "      <td>25.407663</td>\n",
       "      <td>30.277132</td>\n",
       "      <td>22.647445</td>\n",
       "      <td>21.141607</td>\n",
       "      <td>7.861236</td>\n",
       "      <td>19.801784</td>\n",
       "      <td>39.471112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0  19.086043  20.775041  32.662159  27.347059  33.432155   9.001761   \n",
       "1  18.568518  19.923297  18.932132  17.107522  14.266230  24.135877   \n",
       "2  19.809422  32.932002  22.991487  23.752759  20.598338  44.497664   \n",
       "3  17.671078  23.916499  25.919748  19.409376  20.178503  17.916191   \n",
       "4  27.970411  16.878918  15.371155  23.775365  19.159630  47.095129   \n",
       "\n",
       "         6          7          8          9    ...        190        191  \\\n",
       "0  20.030982  28.690798  20.555787   8.942408  ...  45.602515  21.945659   \n",
       "1  20.202173  30.432826  19.002506  37.307498  ...  15.528705  21.573855   \n",
       "2  19.672780  19.524344  28.380861   8.462188  ...  21.248748  19.696959   \n",
       "3  14.835005  14.725457  21.853383  23.238445  ...  17.671723  18.987953   \n",
       "4  13.187261  15.921431  27.086741  33.032481  ...  33.817844  16.624787   \n",
       "\n",
       "         192        193        194        195        196        197  \\\n",
       "0  16.681802  14.369645  34.708164  19.911770  19.250785  26.258703   \n",
       "1  23.874679  13.465219  48.011769  17.491779  21.264077  35.055494   \n",
       "2  44.722984  16.444413  18.726456  20.147961  38.258043  33.436345   \n",
       "3  22.156860  22.247468  27.012871  20.511799  22.881815  20.780752   \n",
       "4  44.027642  25.407663  30.277132  22.647445  21.141607   7.861236   \n",
       "\n",
       "         198        199  \n",
       "0  18.392011  20.915625  \n",
       "1  17.768116  14.787413  \n",
       "2  22.443509  20.509242  \n",
       "3  13.975789  24.301032  \n",
       "4  19.801784  39.471112  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = []\n",
    "for i in range(len(gb.columns)):\n",
    "    r2.append(r2_score(ys[i], gb[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error:  9.74780702292435\n",
      "Test Variance Score:  0.8786720728965828\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in r2:\n",
    "    sum += i\n",
    "print(\"Mean Square Error: \", gb2.mean()[0])\n",
    "print(\"Test Variance Score: \", sum/len(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8** Now compute feature importance using the method we've developed in previous labs. I have two loops here. One is that I rerun train_test_split 50 times as you can see from above this makes a difference. Then I also permute each feature 100 times. Test your code with much smaller numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.193180</td>\n",
       "      <td>8.028808</td>\n",
       "      <td>8.092374</td>\n",
       "      <td>8.115260</td>\n",
       "      <td>8.531025</td>\n",
       "      <td>10.434782</td>\n",
       "      <td>7.257673</td>\n",
       "      <td>8.621556</td>\n",
       "      <td>8.190826</td>\n",
       "      <td>8.564397</td>\n",
       "      <td>8.831632</td>\n",
       "      <td>10.568751</td>\n",
       "      <td>17.801014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15.570545</td>\n",
       "      <td>19.225992</td>\n",
       "      <td>19.523587</td>\n",
       "      <td>19.026854</td>\n",
       "      <td>19.982604</td>\n",
       "      <td>19.412684</td>\n",
       "      <td>19.227216</td>\n",
       "      <td>18.378906</td>\n",
       "      <td>19.171513</td>\n",
       "      <td>18.991553</td>\n",
       "      <td>23.260748</td>\n",
       "      <td>14.532684</td>\n",
       "      <td>30.240799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>23.807312</td>\n",
       "      <td>22.927909</td>\n",
       "      <td>22.322833</td>\n",
       "      <td>23.851036</td>\n",
       "      <td>24.935247</td>\n",
       "      <td>11.157059</td>\n",
       "      <td>22.576945</td>\n",
       "      <td>8.433350</td>\n",
       "      <td>22.421660</td>\n",
       "      <td>24.544193</td>\n",
       "      <td>20.910475</td>\n",
       "      <td>21.842585</td>\n",
       "      <td>34.368237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.820341</td>\n",
       "      <td>10.614135</td>\n",
       "      <td>10.590218</td>\n",
       "      <td>10.335012</td>\n",
       "      <td>11.937606</td>\n",
       "      <td>20.569161</td>\n",
       "      <td>10.761392</td>\n",
       "      <td>14.205016</td>\n",
       "      <td>11.021088</td>\n",
       "      <td>11.185934</td>\n",
       "      <td>8.474175</td>\n",
       "      <td>10.725025</td>\n",
       "      <td>27.795435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.687099</td>\n",
       "      <td>5.693013</td>\n",
       "      <td>6.047145</td>\n",
       "      <td>5.799621</td>\n",
       "      <td>7.858243</td>\n",
       "      <td>14.263353</td>\n",
       "      <td>6.576165</td>\n",
       "      <td>7.666153</td>\n",
       "      <td>6.004824</td>\n",
       "      <td>6.240231</td>\n",
       "      <td>6.119884</td>\n",
       "      <td>7.102066</td>\n",
       "      <td>7.572966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM         ZN      INDUS       CHAS        NOX         RM  \\\n",
       "0   9.193180   8.028808   8.092374   8.115260   8.531025  10.434782   \n",
       "1  15.570545  19.225992  19.523587  19.026854  19.982604  19.412684   \n",
       "2  23.807312  22.927909  22.322833  23.851036  24.935247  11.157059   \n",
       "3  10.820341  10.614135  10.590218  10.335012  11.937606  20.569161   \n",
       "4   6.687099   5.693013   6.047145   5.799621   7.858243  14.263353   \n",
       "\n",
       "         AGE        DIS        RAD        TAX    PTRATIO          B      LSTAT  \n",
       "0   7.257673   8.621556   8.190826   8.564397   8.831632  10.568751  17.801014  \n",
       "1  19.227216  18.378906  19.171513  18.991553  23.260748  14.532684  30.240799  \n",
       "2  22.576945   8.433350  22.421660  24.544193  20.910475  21.842585  34.368237  \n",
       "3  10.761392  14.205016  11.021088  11.185934   8.474175  10.725025  27.795435  \n",
       "4   6.576165   7.666153   6.004824   6.240231   6.119884   7.102066   7.572966  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_iterations = 20\n",
    "experiments = {}\n",
    "df_list = []\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.10,shuffle=True)\n",
    " \n",
    "    models_train = copy.deepcopy(models)\n",
    "    \n",
    "    Xtrain_copy = Xtrain.copy()\n",
    "    \n",
    "    model = models_train[1] #Gradient Boosting 2\n",
    "\n",
    "    for col in Xtrain_copy.columns:\n",
    "        mse = 0\n",
    "        for i in range(10):\n",
    "            Xtrain_copy = Xtrain.copy()\n",
    "            Xtrain_copy[col] = np.random.permutation(Xtrain_copy[col])\n",
    "            m = model[1].fit(Xtrain_copy, ytrain)\n",
    "            mse += mean_squared_error(ytest, m.predict(Xtest))\n",
    "        experiments[col] = [mse/10]\n",
    "\n",
    "    temp = pd.DataFrame(experiments)\n",
    "    df_list.append(temp)\n",
    "    \n",
    "a = pd.concat(df_list)\n",
    "a = a.reset_index(drop=True)\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHAS       0.084533\n",
       "ZN         0.088264\n",
       "B          0.098601\n",
       "RAD        0.100989\n",
       "INDUS      0.107237\n",
       "CRIM       0.117487\n",
       "AGE        0.119132\n",
       "PTRATIO    0.131354\n",
       "TAX        0.168505\n",
       "DIS        0.273435\n",
       "NOX        0.278164\n",
       "RM         0.683283\n",
       "LSTAT      1.147395\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "percent_diff_score = (a.mean(axis=0).sort_values() - gb2.mean()[0])/gb2.mean()[0]\n",
    "display(percent_diff_score)\n",
    "percent_diff_score_data = pd.DataFrame(percent_diff_score, columns=[\"Scores\"])\n",
    "percent_diff_score_data.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running train-test-split 20 times, permuting each column 10 times, and retraining each training set, we see that LSTAT, RM, and NOX appear to be the 3 best features. However, we will replace NOX with DIS, since the later code reveals DIS is actually the third best feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL VARIABLES GB2\n",
    "\n",
    "num_iterations = 30\n",
    "predictions_all_var = []\n",
    "ytests_all_var = []\n",
    "mses_all_var = []\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.10,shuffle=True)\n",
    "    models_train = copy.deepcopy(models)\n",
    "    \n",
    "    model = models_train[1]\n",
    "    \n",
    "    m = model[1].fit(Xtrain, ytrain)\n",
    "    predictions_all_var.append(m.predict(Xtest))\n",
    "    ytests_all_var.append(ytest)\n",
    "    mses_all_var.append(mean_squared_error(ytest, m.predict(Xtest)))\n",
    "    \n",
    "\n",
    "all_var_df = pd.DataFrame(mses_all_var, columns=[\"All Features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUBSET VARIABLES GB2\n",
    "\n",
    "num_iterations = 30\n",
    "predictions_subset = []\n",
    "ytests_subset = []\n",
    "mses_subset = []\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X[[\"DIS\", \"RM\", \"LSTAT\"]],y,test_size=0.10,shuffle=True)\n",
    "    models_train = copy.deepcopy(models)\n",
    "    \n",
    "    model = models_train[1]\n",
    "    \n",
    "    m = model[1].fit(Xtrain, ytrain)\n",
    "    predictions_subset.append(m.predict(Xtest))\n",
    "    ytests_subset.append(ytest)\n",
    "    mses_subset.append(mean_squared_error(ytest, m.predict(Xtest)))\n",
    "    \n",
    "\n",
    "subset_df = pd.DataFrame(mses_subset, columns=[\"Subset Features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All Features</th>\n",
       "      <th>Subset Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>11.053123</td>\n",
       "      <td>18.302574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>6.996503</td>\n",
       "      <td>8.013504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>4.518106</td>\n",
       "      <td>8.023697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>7.202934</td>\n",
       "      <td>13.182885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>9.388140</td>\n",
       "      <td>16.025886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>12.325122</td>\n",
       "      <td>23.009161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>40.723584</td>\n",
       "      <td>39.727169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       All Features  Subset Features\n",
       "count     30.000000        30.000000\n",
       "mean      11.053123        18.302574\n",
       "std        6.996503         8.013504\n",
       "min        4.518106         8.023697\n",
       "25%        7.202934        13.182885\n",
       "50%        9.388140        16.025886\n",
       "75%       12.325122        23.009161\n",
       "max       40.723584        39.727169"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = all_var_df.join(subset_df, how=\"left\")\n",
    "errors.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the subset features, we see a higher mean MSE and standard deviation of the MSE's after 30 iterations. At each quantile, the subset features yielded sligher higher MSE value estimates. Overall however, the subset features performs nearly just as well as using all features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9** Now what if I told you that Random Forest and other classifiers have built-in measures for feature importance. Run the following code and compare the feature importance scores. The calculation of these needs to be saved for another time and place, but the trees themselves contain information about feature importance based on the location in the tree a feature is most often selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2a2c588710>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "forest = RandomForestRegressor(n_estimators=500)\n",
    "forest.fit(X,y)\n",
    "importances = forest.feature_importances_\n",
    "importances = pd.DataFrame({'Feature':X.columns,'Importance':importances})\n",
    "importances.sort_values(by='Importance').set_index('Feature').plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn best features testing reveals that RM, LSTAT, and DIS are the best features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation from scratch portion**: We are now going to implement two ensemble learning methods from scratch and see how our implementations compare to sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10** Implement a simple random forest classifier and compare the performance to one of the random forest classifiers above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def boostrap_sample(X, y, frac=0.3):\n",
    "    Xy = X.copy()\n",
    "    Xy[y.name] = y\n",
    "    Xy_sample = Xy.sample(frac=frac,replace=True)\n",
    "    \n",
    "    return Xy.drop(y.name,axis=1),Xy[y.name]\n",
    "\n",
    "\n",
    "def make_tree(X, y, m=None):\n",
    "    if m is None:\n",
    "        m = int(np.sqrt(X.shape[1]))\n",
    "        \n",
    "    nums = np.random.rand(X.shape[1])\n",
    "    vs = pd.DataFrame({\"num\":nums})\n",
    "    vs = vs.sort_values(by='num')\n",
    "    features = vs.index\n",
    "    Xf = X.iloc[:,features]\n",
    "    \n",
    "    return features, DecisionTreeRegressor(random_state=0).fit(Xf, y)\n",
    "\n",
    "\n",
    "def make_trees(X, y, ntrees=100, m=None, frac=0.3):\n",
    "    trees = []\n",
    "    for i in range(ntrees):\n",
    "        Xsample, ysample = boostrap_sample(X, y, frac=frac)\n",
    "        trees.append(make_tree(Xsample, ysample, m=m))\n",
    "        \n",
    "    return trees\n",
    "\n",
    "\n",
    "def make_prediction(trees, X):\n",
    "    predictions = []\n",
    "    tree_predictions = []\n",
    "    for j in range(len(trees)):\n",
    "        features = trees[j][0]\n",
    "        tree = trees[j][1]\n",
    "        tree_predictions.append(tree.predict(X.iloc[:,features])) \n",
    "    return tree_predictions\n",
    "    \n",
    "    \n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.10, shuffle=True)\n",
    "mses = []\n",
    "for i in range(20):\n",
    "    temp = []\n",
    "    trees = make_trees(Xtrain, ytrain)\n",
    "    predictions = make_prediction(trees, Xtest)\n",
    "    for i in range(len(predictions)):\n",
    "        temp.append(mean_squared_error(ytest, predictions[i]))\n",
    "    mses.append(np.mean(temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Our RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>21.659359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>21.874916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21.181827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>21.715788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>21.824492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Our RF\n",
       "0  21.659359\n",
       "1  21.874916\n",
       "2  21.181827\n",
       "3  21.715788\n",
       "4  21.824492"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_mses = pd.DataFrame(mses, columns=[\"Our RF\"])\n",
    "our_mses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF 1</th>\n",
       "      <th>Our RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.788218</td>\n",
       "      <td>21.659359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15.413025</td>\n",
       "      <td>21.874916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.778086</td>\n",
       "      <td>21.181827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.365300</td>\n",
       "      <td>21.715788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.079514</td>\n",
       "      <td>21.824492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RF 1     Our RF\n",
       "0   7.788218  21.659359\n",
       "1  15.413025  21.874916\n",
       "2   9.778086  21.181827\n",
       "3  11.365300  21.715788\n",
       "4   7.079514  21.824492"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_rf_errors = rf1.join(our_mses, how=\"left\")\n",
    "compare_rf_errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF 1</th>\n",
       "      <th>Our RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>10.924009</td>\n",
       "      <td>21.657684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>5.065647</td>\n",
       "      <td>0.221101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>3.784835</td>\n",
       "      <td>21.181827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>7.354933</td>\n",
       "      <td>21.499527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>9.377936</td>\n",
       "      <td>21.687574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>13.440044</td>\n",
       "      <td>21.808270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>31.849355</td>\n",
       "      <td>22.106139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             RF 1     Our RF\n",
       "count  200.000000  20.000000\n",
       "mean    10.924009  21.657684\n",
       "std      5.065647   0.221101\n",
       "min      3.784835  21.181827\n",
       "25%      7.354933  21.499527\n",
       "50%      9.377936  21.687574\n",
       "75%     13.440044  21.808270\n",
       "max     31.849355  22.106139"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_rf_errors.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RF model gives much more precise scores in comparison to the scikit-learn random foresting model however, by the MSE values, our model is not as accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10** Implement gradient boosting from scratch using a mean squared error loss function. Compare the performance. I \"boosted\" 100 times. I've shown my validation graph. Every run is a little different, and it would definitely make this algorithm smarter if you stopped based on the validation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residuals(actual, predictions):\n",
    "    return actual - predictions\n",
    "   \n",
    "def make_tree(X, y, m=None):\n",
    "    Xresids = get_residuals(y, X[\"prediction\"])\n",
    "   \n",
    "    if m is None:\n",
    "        m = int(np.sqrt(X.shape[1]))\n",
    "       \n",
    "    nums = np.random.rand(X.shape[1])\n",
    "    vs = pd.DataFrame({\"num\":nums})\n",
    "    vs = vs.sort_values(by='num')\n",
    "    features = vs.index\n",
    "    Xf = X.iloc[:,features]\n",
    "   \n",
    "    return features, DecisionTreeRegressor(random_state=0).fit(Xf, Xresids)\n",
    " \n",
    "def make_trees(X, y, ntrees=1, m=None, frac=0.3):\n",
    "    trees = []\n",
    "    for i in range(ntrees):\n",
    "        trees.append(make_tree(X, y, m=m))\n",
    "       \n",
    "    return trees\n",
    " \n",
    "def make_prediction(trees, X):\n",
    "    predictions = []\n",
    "    tree_predictions = []\n",
    "    #for j in range(len(trees)):\n",
    "    features = trees[0]\n",
    "    tree = trees[1]\n",
    "    return tree.predict(X.iloc[:,features])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2a2c5332e8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.75, shuffle=True)\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.75, shuffle=True)\n",
    " \n",
    "Xtrain[\"prediction\"] = ytrain.mean()\n",
    "Xval[\"prediction\"] = yval.mean()\n",
    " \n",
    "mse_list = []\n",
    "tree_list = []\n",
    "for i in range(100):\n",
    "    tree = make_tree(Xtrain, ytrain)\n",
    "    tree_list.append(tree)\n",
    "    predictions = make_prediction(tree, Xtrain)\n",
    "    Xtrain[\"prediction\"] = Xtrain[\"prediction\"] + 0.1*predictions\n",
    "    valpredictions = make_prediction(tree, Xval)\n",
    "    Xval[\"prediction\"] = Xval[\"prediction\"] + 0.1*valpredictions\n",
    "    mse1 = mean_squared_error(yval, Xval[\"prediction\"])\n",
    "\n",
    "    mse_list.append(mse1)\n",
    "       \n",
    "pd.DataFrame(mse_list, columns=[\"Validation\"]).plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.32527777008309"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "minidx = pd.DataFrame(mse_list).idxmin()\n",
    "minidx[0]\n",
    " \n",
    "finaltree = tree_list[minidx[0]]\n",
    " \n",
    "Xtest[\"prediction\"] = ytest.mean()\n",
    "predictions = make_prediction(finaltree, Xtest)\n",
    "mean_squared_error(ytest, Xtest[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
